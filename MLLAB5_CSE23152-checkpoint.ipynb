{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54f92bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\saswat\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\saswat\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\saswat\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "849de9d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Predictions: [2.3583618  2.26897099 2.35871357 2.3729983  2.37665259]\n",
      "Test Predictions: [2.38788876 2.42262009 2.40487585 2.3569433  2.36478988]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "def train_linear_regression_model(X_train, y_train):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Use one feature\n",
    "X = df[[\"embedding_0\"]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = train_linear_regression_model(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Output results\n",
    "print(\"Train Predictions:\", y_train_pred[:5])\n",
    "print(\"Test Predictions:\", y_test_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06fc6b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.519312349012836\n",
      "RMSE: 0.7206332971857712\n",
      "MAPE: 0.36429633067533557\n",
      "R² Score: -0.002986062652017507\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Use one embedding feature (embedding_0)\n",
    "X = df[[\"embedding_0\"]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Split into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"R² Score:\", r2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f766ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 predictions on test set: [2.52006721 2.67136752 2.43934959 2.84266422 2.9987155 ]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Select all embedding columns\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"First 5 predictions on test set:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b56a973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [3 3 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Binary classification: Ensure labels are 0 or 1\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values  # Ensure integer labels\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train logistic regression classifier\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Predictions:\", y_pred[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "197fc57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.67      0.02      0.04        92\n",
      "           2       0.45      0.33      0.38       213\n",
      "           3       0.59      0.83      0.69       358\n",
      "\n",
      "    accuracy                           0.56       663\n",
      "   macro avg       0.57      0.39      0.37       663\n",
      "weighted avg       0.55      0.56      0.50       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "# Features and target\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Classification report\n",
    "y_pred = model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06d7637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA output shape: (3311, 2)\n",
      "First 5 PCA components:\n",
      " [[  5.3229746    2.46619942]\n",
      " [  5.09184631   4.46762507]\n",
      " [ -0.95173992   8.10320349]\n",
      " [-12.05146419  -1.09633618]\n",
      " [  3.91290967  -3.2813958 ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to reduce dimensions to 2\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"PCA output shape:\", X_pca.shape)\n",
    "print(\"First 5 PCA components:\\n\", X_pca[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c33362a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00        92\n",
      "           2       0.40      0.01      0.02       213\n",
      "           3       0.54      0.99      0.70       358\n",
      "\n",
      "    accuracy                           0.54       663\n",
      "   macro avg       0.31      0.33      0.24       663\n",
      "weighted avg       0.42      0.54      0.38       663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saswat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Saswat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Saswat\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"embedded_dataset_deberta.csv\")\n",
    "df = df.dropna(subset=[\"label\"])\n",
    "\n",
    "X = df[[col for col in df.columns if col.startswith(\"embedding_\")]].values\n",
    "y = df[\"label\"].astype(int).values\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fc1d7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
